{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccad427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "n_targets = 5\n",
    "n_samples = 10\n",
    "n_features = 3\n",
    "mt_explanation_per_sample = [\n",
    "    tuple (\n",
    "        torch.randn(1, 100) for _ in range(n_features)\n",
    "    ) for _ in range(n_targets)\n",
    "]\n",
    "\n",
    "mt_explanations_btf = [mt_explanation_per_sample for _ in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8fcdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_explanations_tbf = list(map(list, zip(*mt_explanations_btf, strict=True))) # perform outer transpose (B, T, F) -> (T, B, F)\n",
    "mt_explanations_tfb = [tuple(map(torch.cat, zip(*target_explanations_bf, strict=True))) for target_explanations_bf in mt_explanations_tbf]  # perform inner transpose (B, F) -> (F, B)\n",
    "\n",
    "for target_explanations_fb in mt_explanations_tfb:\n",
    "    assert len(target_explanations_fb) == 3  # Should be n_features\n",
    "    assert isinstance(target_explanations_fb, tuple)\n",
    "    for feature_explanations_b in target_explanations_fb:\n",
    "        assert feature_explanations_b.shape == (10, 100)  # Should be (n_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atria_insights.data_types._explanation_state import MultiTargetBatchExplanation, MultiTargetSampleExplanation\n",
    "\n",
    "data =[MultiTargetSampleExplanation(value=mt_explanation_per_sample) for _ in range(n_samples)]\n",
    "sample_mt_explanations = []\n",
    "for d in data:\n",
    "    assert isinstance(d, MultiTargetSampleExplanation), (\n",
    "        \"All explanations must be of type SampleMultiTargetExplanation in multi-target case.\"\n",
    "    )\n",
    "    sample_mt_explanations.append(d)\n",
    "batch_mt_explanations = MultiTargetBatchExplanation.fromlist(\n",
    "    sample_mt_explanations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cb88dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SampleMultiTargetExplanation' object has no attribute 'explanations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mt_explanations = \u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplanations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# explanations_list is now a list of lists of tuples\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# first list is per sample\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# second list is per target\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# tuple is the explanation tensors for that target with each tensor in tuple having shape (1, ...)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# we need to transpose this into list of tuples of lists\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# so that we can batch per target\u001b[39;00m\n\u001b[32m      8\u001b[39m transposed_mt_explanations = [\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(*mt_explanations_per_sample, strict=\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m mt_explanations_per_sample \u001b[38;5;129;01min\u001b[39;00m mt_explanations\n\u001b[32m     11\u001b[39m ]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mt_explanations = [\u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplanations\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# explanations_list is now a list of lists of tuples\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# first list is per sample\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# second list is per target\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# tuple is the explanation tensors for that target with each tensor in tuple having shape (1, ...)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# we need to transpose this into list of tuples of lists\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# so that we can batch per target\u001b[39;00m\n\u001b[32m      8\u001b[39m transposed_mt_explanations = [\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(*mt_explanations_per_sample, strict=\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m mt_explanations_per_sample \u001b[38;5;129;01min\u001b[39;00m mt_explanations\n\u001b[32m     11\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/noel/phd-2026/projects/atria/.venv/lib/python3.11/site-packages/pydantic/main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SampleMultiTargetExplanation' object has no attribute 'explanations'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mt_explanations = [d.explanations for d in data]\n",
    "# explanations_list is now a list of lists of tuples\n",
    "# first list is per sample\n",
    "# second list is per target\n",
    "# tuple is the explanation tensors for that target with each tensor in tuple having shape (1, ...)\n",
    "# we need to transpose this into list of tuples of lists\n",
    "# so that we can batch per target\n",
    "transposed_mt_explanations = [\n",
    "    tuple(map(list, zip(*mt_explanations_per_sample, strict=True)))\n",
    "    for mt_explanations_per_sample in mt_explanations\n",
    "]\n",
    "print(\"transposed_explanations\", transposed_mt_explanations)\n",
    "total_samples = len(data)\n",
    "total_targets = len(transposed_mt_explanations[0])\n",
    "for sample_explanations in transposed_mt_explanations:\n",
    "    assert len(sample_explanations) == total_targets, (\n",
    "        \"Each sample's explanations must match the total number of targets.\"\n",
    "    )\n",
    "    for explanation in sample_explanations:\n",
    "        assert len(explanation) == total_samples, (\n",
    "            \"Each explanation list must match the total number of samples.\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atriaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
